# SP24-Gaze-Controlled-Keyboard-Inspired-By-SSVEP-Methods

Brian Tan, Septia Rani

## Project Description
In this project, we aim to create a simple gaze-controlled keyboard that will be accessible to the public. The method is inspired by the Steady-State Visually Evoked Potential (SSVEP). However, it should be noted that the system that we create is not a Brain-Computer Interface (BCI). The prototype is developed using Python programming language.

## Link to videos:
- Short Video (Project Overview): https://www.youtube.com/watch?v=NloH1WRNrDI
- Demo+Code Video: https://www.youtube.com/watch?v=D7LJ5r6ECdk
- Tscan experiment: https://youtu.be/F_Db3on5mkw

## Link to GitHub:
https://github.com/csu-hci-projects/SP24-Gaze-Controlled-Keyboard-Inspired-By-SSVEP-Methods

## What resources are needed (pre-requisite to run the program):
- Install Python 3.11.
- The computer/laptop should have a webcam.

## How to run the project:
1. Download the code from the following GitHub repository:
https://github.com/csu-hci-projects/SP24-Gaze-Controlled-Keyboard-Inspired-By-SSVEP-Methods
2. Open the terminal/command prompt on your computer.
3. On the terminal, change the active directory to the directory of the project.
4. To run the main prototype, type the following command on the terminal: 
>> python mainframe.py
Follow the instructions on the screen.
5. To run the Tscan user study, type the following command on the terminal:
>> python tscan_user_study.py
Follow the instructions on the screen. At the end of the experiment, it will create an Excel file containing the recorded data from the experiments.